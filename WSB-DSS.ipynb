{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3752257b-7b64-4cbe-bf58-7b4e083bfdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa735542-99b3-4ca6-9f10-be27033c7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, install deps. Commented by default.\n",
    "# %pip install pandas numpy scikit-learn duckdb matplotlib pyarrow\n",
    "\n",
    "import os, gc, math, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b263362b-40e4-48d8-8a3c-aad1d4aeca22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "353fd39f-cc6a-4376-a528-f3b5a5109f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files are already present.\n",
      "CSVs present: True\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from pathlib import Path\n",
    "import os, json\n",
    "\n",
    "data_dir = Path('G:/Master\\'s Studies/Uni WSB/4th Sem/Decision Support System/WSB-DSS/data/airbnb_seattle')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "needed = [\n",
    "    'listings.csv',\n",
    "    'calendar.csv',\n",
    "    'reviews.csv'\n",
    "]\n",
    "\n",
    "def have_csvs(d):\n",
    "    return all((d / f).exists() for f in needed)\n",
    "\n",
    "if not have_csvs(data_dir):\n",
    "    print('Attempting Kaggle download...')\n",
    "    \n",
    "    # 1. Define the path to your JSON file\n",
    "    config_path = Path('G:/Master\\'s Studies/Uni WSB/4th Sem/Decision Support System/WSB-DSS/kaggle_key') / 'kaggle.json'\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        print(f\"Kaggle download failed: '{config_path}' not found.\")\n",
    "    else:\n",
    "        try:\n",
    "            # 2. Read the credentials from your file\n",
    "            with open(config_path, 'r') as f:\n",
    "                creds = json.load(f)\n",
    "            \n",
    "            # 3. Set credentials *temporarily* for the API\n",
    "            os.environ['KAGGLE_USERNAME'] = creds['username']\n",
    "            os.environ['KAGGLE_KEY'] = creds['key']\n",
    "            \n",
    "            # 4. Initialize and use the Python API\n",
    "            api = KaggleApi()\n",
    "            api.authenticate()  # This will now succeed\n",
    "            \n",
    "            print('Downloading dataset to', str(data_dir))\n",
    "            api.dataset_download_files(\n",
    "                'airbnb/seattle', \n",
    "                path=str(data_dir), \n",
    "                unzip=True\n",
    "            )\n",
    "            print('Kaggle download complete.')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Kaggle download failed. Error: {e}')\n",
    "else:\n",
    "    print(\"CSV files are already present.\")\n",
    "\n",
    "print('CSVs present:', have_csvs(data_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cabf385-30ac-466f-9b98-d32a29c74d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] listings.csv\n",
      "[OK] calendar.csv\n",
      "[OK] reviews.csv\n",
      "Shapes: (3818, 92) (1393570, 4) (84849, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Assumes `data_dir` already points to your Seattle Airbnb folder\n",
    "files = {\n",
    "    'listings': data_dir / 'listings.csv',\n",
    "    'calendar': data_dir / 'calendar.csv',\n",
    "    'reviews' : data_dir / 'reviews.csv'\n",
    "}\n",
    "\n",
    "# Minimal required columns to confirm we're looking at the right schema\n",
    "required = {\n",
    "    'listings': ['id', 'host_id', 'price'],\n",
    "    'calendar': ['listing_id', 'date', 'available', 'price'],\n",
    "    'reviews' : ['listing_id', 'date', 'comments']\n",
    "}\n",
    "\n",
    "def check_csv(path: Path, required_cols):\n",
    "    if not path.exists():\n",
    "        print(f\"[MISSING] {path}\")\n",
    "        return False\n",
    "    # Read only header to avoid heavy IO\n",
    "    cols = pd.read_csv(path, nrows=0).columns.str.lower().tolist()\n",
    "    missing = [c for c in required_cols if c.lower() not in cols]\n",
    "    if missing:\n",
    "        print(f\"[CHECK] {path.name}: missing expected columns: {missing}\")\n",
    "        return False\n",
    "    print(f\"[OK] {path.name}\")\n",
    "    return True\n",
    "\n",
    "all_ok = True\n",
    "for k, p in files.items():\n",
    "    all_ok &= check_csv(p, required[k])\n",
    "\n",
    "# Load the data (parse date columns if present; safe even if some are missing)\n",
    "listings = pd.read_csv(files['listings'])\n",
    "for col in ['host_since', 'first_review', 'last_review', 'calendar_last_scraped', 'last_scraped']:\n",
    "    if col in listings.columns:\n",
    "        listings[col] = pd.to_datetime(listings[col], errors='coerce')\n",
    "\n",
    "calendar = pd.read_csv(files['calendar'])\n",
    "if 'date' in calendar.columns:\n",
    "    calendar['date'] = pd.to_datetime(calendar['date'], errors='coerce')\n",
    "\n",
    "reviews = pd.read_csv(files['reviews'])\n",
    "if 'date' in reviews.columns:\n",
    "    reviews['date'] = pd.to_datetime(reviews['date'], errors='coerce')\n",
    "\n",
    "print('Shapes:', listings.shape, calendar.shape, reviews.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c8f3d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run tracking + artifact saving (DuckDB + filesystem) for regression / logistic / kmeans ===\n",
    "import os, json, uuid, datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import duckdb\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Config ----------\n",
    "DB_PATH  = Path(\"wsb_dss.duckdb\")\n",
    "ART_ROOT = Path(\"artifacts\")\n",
    "ART_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- DB helpers ----------\n",
    "def _con():\n",
    "    con = duckdb.connect(str(DB_PATH))\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS runs (\n",
    "            run_id TEXT PRIMARY KEY,\n",
    "            model_type TEXT,\n",
    "            started_at TIMESTAMP,\n",
    "            ended_at TIMESTAMP,\n",
    "            status TEXT,              -- 'running'|'succeeded'|'failed'\n",
    "            params TEXT,              -- JSON string\n",
    "            metrics TEXT,             -- JSON string\n",
    "            dataset_id TEXT,\n",
    "            notes TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS artifacts (\n",
    "            run_id TEXT,\n",
    "            artifact_type TEXT,       -- 'plot'|'table'|'model'|'text'\n",
    "            uri TEXT,                 -- relative path\n",
    "            description TEXT,\n",
    "            PRIMARY KEY (run_id, artifact_type, uri)\n",
    "        );\n",
    "    \"\"\")\n",
    "    return con\n",
    "\n",
    "def start_run(model_type, params=None, dataset_id=\"airbnb_seattle\"):\n",
    "    run_id = f\"{dt.datetime.now():%Y%m%d-%H%M%S}-{model_type}-{str(uuid.uuid4())[:8]}\"\n",
    "    _con().execute(\"INSERT INTO runs VALUES (?,?,?,?,?,?,?,?,?)\",\n",
    "                   [run_id, model_type, dt.datetime.now(), None, 'running',\n",
    "                    json.dumps(params or {}), None, dataset_id, None])\n",
    "    return run_id\n",
    "\n",
    "def end_run(run_id, status='succeeded', metrics=None, notes=None):\n",
    "    _con().execute(\"\"\"\n",
    "        UPDATE runs SET ended_at=?, status=?, metrics=?, notes=? WHERE run_id=?\n",
    "    \"\"\", [dt.datetime.now(), status, json.dumps(metrics or {}), notes, run_id])\n",
    "\n",
    "# --- helper: ensure run row exists when a run_id is provided externally ---\n",
    "def _ensure_run_row(run_id, model_type, params=None, dataset_id=\"airbnb_seattle\"):\n",
    "    row = _con().execute(\"SELECT 1 FROM runs WHERE run_id=?\", [run_id]).fetchone()\n",
    "    if row is None:\n",
    "        _con().execute(\n",
    "            \"INSERT INTO runs VALUES (?,?,?,?,?,?,?,?,?)\",\n",
    "            [run_id, model_type, dt.datetime.now(), None, 'running',\n",
    "             json.dumps(params or {}), None, dataset_id, None]\n",
    "        )\n",
    "\n",
    "\n",
    "def log_artifact(run_id, path, artifact_type='plot', description=''):\n",
    "    rel = str(Path(path))\n",
    "    _con().execute(\"INSERT OR REPLACE INTO artifacts VALUES (?,?,?,?)\",\n",
    "                   [run_id, artifact_type, rel, description])\n",
    "\n",
    "def latest_run(model_type):\n",
    "    return _con().execute(\"\"\"\n",
    "        SELECT * FROM runs WHERE model_type=? ORDER BY ended_at DESC NULLS LAST, started_at DESC LIMIT 1\n",
    "    \"\"\", [model_type]).df()\n",
    "\n",
    "def runs_history(model_type=None):\n",
    "    if model_type:\n",
    "        return _con().execute(\"SELECT * FROM runs WHERE model_type=? ORDER BY started_at DESC\", [model_type]).df()\n",
    "    return _con().execute(\"SELECT * FROM runs ORDER BY started_at DESC\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a535da68-fae7-4e78-8ed3-f629261ab921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Audit tables (no history) + persist helpers ============================\n",
    "import json, datetime as dt\n",
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Create the two singleton audit tables (1 row per dataset_id)\n",
    "def ensure_audit_tables():\n",
    "    con = _con()\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS health_checks (\n",
    "            dataset_id TEXT PRIMARY KEY,\n",
    "            computed_at TIMESTAMP,\n",
    "            metrics TEXT            -- JSON\n",
    "        );\n",
    "    \"\"\")\n",
    "    con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS deep_dive_checks (\n",
    "            dataset_id TEXT PRIMARY KEY,\n",
    "            computed_at TIMESTAMP,\n",
    "            metrics TEXT            -- JSON\n",
    "        );\n",
    "    \"\"\")\n",
    "    # Auxiliary tables for detailed frames (we replace them entirely on persist)\n",
    "    # We store one copy per dataset in each table via a dataset_id column.\n",
    "    # Tables are created on first persist.\n",
    "\n",
    "ensure_audit_tables()\n",
    "\n",
    "def _df_to_table(con, df: pd.DataFrame, table_name: str, dataset_id: str):\n",
    "    df = df.copy()\n",
    "    df.insert(0, \"dataset_id\", dataset_id)\n",
    "    con.execute(f\"CREATE TABLE IF NOT EXISTS {table_name} AS SELECT * FROM df LIMIT 0\")\n",
    "    # Replace the whole table for this dataset_id\n",
    "    con.execute(f\"DELETE FROM {table_name} WHERE dataset_id = ?\", [dataset_id])\n",
    "    con.register(\"df\", df)\n",
    "    con.execute(f\"INSERT INTO {table_name} SELECT * FROM df\")\n",
    "    con.unregister(\"df\")\n",
    "\n",
    "def persist_health_audit(audit: dict, dataset_id=\"airbnb_seattle\", overwrite=False, verbose=True):\n",
    "    \"\"\"\n",
    "    audit: dict from run_health_audit(...): {'metrics': {...}, 'tables': {...}}\n",
    "    Writes a single row to health_checks; stores detailed frames in *_health_* tables.\n",
    "    \"\"\"\n",
    "    con = _con()\n",
    "    # skip if exists and not overwriting\n",
    "    exists = con.execute(\"SELECT 1 FROM health_checks WHERE dataset_id=?\", [dataset_id]).fetchone() is not None\n",
    "    if exists and not overwrite:\n",
    "        if verbose: print(f\"[health_checks] Row already exists for dataset_id='{dataset_id}'. Skipping (overwrite=False).\")\n",
    "        return\n",
    "\n",
    "    # upsert the JSON metrics row\n",
    "    con.execute(\"DELETE FROM health_checks WHERE dataset_id=?\", [dataset_id])\n",
    "    con.execute(\n",
    "        \"INSERT INTO health_checks VALUES (?,?,?)\",\n",
    "        [dataset_id, dt.datetime.now(), json.dumps(audit.get(\"metrics\", {}))]\n",
    "    )\n",
    "\n",
    "    # store detailed tables (replace per dataset_id)\n",
    "    tbls = audit.get(\"tables\", {})\n",
    "    if isinstance(tbls.get(\"missing_listings\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"missing_listings\"], \"detail_health_missing_listings\", dataset_id)\n",
    "    if isinstance(tbls.get(\"missing_calendar\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"missing_calendar\"], \"detail_health_missing_calendar\", dataset_id)\n",
    "    if isinstance(tbls.get(\"missing_reviews\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"missing_reviews\"], \"detail_health_missing_reviews\", dataset_id)\n",
    "    if isinstance(tbls.get(\"bad_avail_examples\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"bad_avail_examples\"], \"detail_health_bad_availability\", dataset_id)\n",
    "    if isinstance(tbls.get(\"rev_consistency_sample\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"rev_consistency_sample\"], \"detail_health_review_consistency\", dataset_id)\n",
    "    if isinstance(tbls.get(\"price_summaries\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"price_summaries\"], \"detail_health_price_summaries\", dataset_id)\n",
    "\n",
    "    if verbose: print(f\"[health_checks] Persisted for dataset_id='{dataset_id}'.\")\n",
    "\n",
    "def persist_deep_dive_audit(audit: dict, dataset_id=\"airbnb_seattle\", overwrite=False, verbose=True):\n",
    "    \"\"\"\n",
    "    audit: dict from run_deep_dive_audit(...): {'metrics': {...}, 'tables': {...}}\n",
    "    Writes a single row to deep_dive_checks; stores frames in *_deepdive_* tables.\n",
    "    \"\"\"\n",
    "    con = _con()\n",
    "    exists = con.execute(\"SELECT 1 FROM deep_dive_checks WHERE dataset_id=?\", [dataset_id]).fetchone() is not None\n",
    "    if exists and not overwrite:\n",
    "        if verbose: print(f\"[deep_dive_checks] Row already exists for dataset_id='{dataset_id}'. Skipping (overwrite=False).\")\n",
    "        return\n",
    "\n",
    "    con.execute(\"DELETE FROM deep_dive_checks WHERE dataset_id=?\", [dataset_id])\n",
    "    con.execute(\n",
    "        \"INSERT INTO deep_dive_checks VALUES (?,?,?)\",\n",
    "        [dataset_id, dt.datetime.now(), json.dumps(audit.get(\"metrics\", {}))]\n",
    "    )\n",
    "\n",
    "    tbls = audit.get(\"tables\", {})\n",
    "    if isinstance(tbls.get(\"miss_by_avail\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"miss_by_avail\"], \"detail_deepdive_price_missing_by_avail\", dataset_id)\n",
    "    if isinstance(tbls.get(\"occ_by_listing\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"occ_by_listing\"], \"detail_deepdive_occupancy_by_listing\", dataset_id)\n",
    "    if isinstance(tbls.get(\"gap_summary\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"gap_summary\"], \"detail_deepdive_gap_summary\", dataset_id)\n",
    "    if isinstance(tbls.get(\"notable_gaps\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"notable_gaps\"], \"detail_deepdive_notable_gaps\", dataset_id)\n",
    "    if isinstance(tbls.get(\"rev_stats\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"rev_stats\"], \"detail_deepdive_review_stats\", dataset_id)\n",
    "    if isinstance(tbls.get(\"top_neighborhoods\"), pd.DataFrame):\n",
    "        _df_to_table(con, tbls[\"top_neighborhoods\"], \"detail_deepdive_top_neighborhoods\", dataset_id)\n",
    "\n",
    "    if verbose: print(f\"[deep_dive_checks] Persisted for dataset_id='{dataset_id}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "231dc1d4-5256-4b32-92fc-2a3bcff94af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Health audit (turns your quick health check into structured outputs) ===\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def run_health_audit(listings: pd.DataFrame, calendar: pd.DataFrame, reviews: pd.DataFrame, verbose=True):\n",
    "    def money_to_float(s):\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            return s.astype(float)\n",
    "        return (s.astype(str).str.replace(r'[^0-9.\\-]', '', regex=True)\n",
    "                    .replace({'': np.nan, '.': np.nan}).astype(float))\n",
    "\n",
    "    # normalize copies to avoid side-effects\n",
    "    L = listings.copy()\n",
    "    C = calendar.copy()\n",
    "    R = reviews.copy()\n",
    "\n",
    "    # derived columns (non-destructive for caller)\n",
    "    if 'price' in L.columns and 'price_num' not in L.columns:\n",
    "        L['price_num'] = money_to_float(L['price'])\n",
    "    if 'price' in C.columns and 'price_num' not in C.columns:\n",
    "        C['price_num'] = money_to_float(C['price'])\n",
    "    if 'available' in C.columns:\n",
    "        C['available_norm'] = C['available'].astype(str).str.lower().str.strip()\n",
    "\n",
    "    # shapes\n",
    "    rows_cols = {\n",
    "        \"listings_rows\": int(L.shape[0]), \"listings_cols\": int(L.shape[1]),\n",
    "        \"calendar_rows\": int(C.shape[0]), \"calendar_cols\": int(C.shape[1]),\n",
    "        \"reviews_rows\":  int(R.shape[0]), \"reviews_cols\":  int(R.shape[1]),\n",
    "    }\n",
    "\n",
    "    # missingness (full, but we’ll store as frames)\n",
    "    miss_L = L.isna().mean().sort_values(ascending=False).to_frame(\"missing_pct\").mul(100).round(2)\n",
    "    miss_C = C.isna().mean().sort_values(ascending=False).to_frame(\"missing_pct\").mul(100).round(2)\n",
    "    miss_R = R.isna().mean().sort_values(ascending=False).to_frame(\"missing_pct\").mul(100).round(2)\n",
    "\n",
    "    # duplicates\n",
    "    dup_list = int(L['id'].duplicated().sum()) if 'id' in L.columns else None\n",
    "    dup_cal = int(C.duplicated(['listing_id','date']).sum()) if {'listing_id','date'}.issubset(C.columns) else None\n",
    "    rev_subset = [c for c in ['listing_id','date','reviewer_id','id'] if c in R.columns]\n",
    "    dup_rev = int(R.duplicated(rev_subset).sum()) if len(rev_subset) >= 2 else None\n",
    "\n",
    "    # referential integrity\n",
    "    cal_missing = int((~C['listing_id'].isin(L['id'])).sum()) if {'listing_id'}.issubset(C.columns) and 'id' in L.columns else None\n",
    "    rev_missing = int((~R['listing_id'].isin(L['id'])).sum()) if {'listing_id'}.issubset(R.columns) and 'id' in L.columns else None\n",
    "\n",
    "    # dates (only ranges)\n",
    "    def _range(df, col):\n",
    "        if col in df.columns and pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            return str(df[col].min()), str(df[col].max())\n",
    "        return None, None\n",
    "    date_ranges = {\n",
    "        \"listings.host_since\": _range(L,'host_since'),\n",
    "        \"listings.first_review\": _range(L,'first_review'),\n",
    "        \"listings.last_review\": _range(L,'last_review'),\n",
    "        \"listings.calendar_last_scraped\": _range(L,'calendar_last_scraped'),\n",
    "        \"listings.last_scraped\": _range(L,'last_scraped'),\n",
    "        \"calendar.date\": _range(C,'date'),\n",
    "        \"reviews.date\": _range(R,'date'),\n",
    "    }\n",
    "\n",
    "    # compare listings' first/last_review vs reviews min/max (counts only + sample mismatches)\n",
    "    rev_span = None; comp = None\n",
    "    first_mismatch = last_mismatch = None\n",
    "    if {'listing_id','date'}.issubset(R.columns) and {'id','first_review','last_review'}.issubset(L.columns):\n",
    "        rev_span = R.groupby('listing_id')['date'].agg(['min','max']).rename(columns={'min':'rev_min','max':'rev_max'})\n",
    "        comp = L.set_index('id')[['first_review','last_review']].join(rev_span, how='left')\n",
    "        first_mismatch = int(((~comp['first_review'].isna()) & (~comp['rev_min'].isna()) & (comp['first_review'] != comp['rev_min'])).sum())\n",
    "        last_mismatch  = int(((~comp['last_review'].isna())  & (~comp['rev_max'].isna()) & (comp['last_review']  != comp['rev_max'])).sum())\n",
    "\n",
    "    # price summaries\n",
    "    def price_summary(s, name):\n",
    "        v = pd.to_numeric(s, errors='coerce').dropna()\n",
    "        if v.empty: return {\"N\":0}\n",
    "        q = v.quantile([0.01,0.05,0.5,0.95,0.99])\n",
    "        return {\n",
    "            \"N\": int(v.size), \"min\": float(v.min()), \"p1\": float(q.iloc[0]), \"p5\": float(q.iloc[1]),\n",
    "            \"median\": float(q.iloc[2]), \"p95\": float(q.iloc[3]), \"p99\": float(q.iloc[4]),\n",
    "            \"max\": float(v.max()), \"zeros\": int((v==0).sum()), \"negatives\": int((v<0).sum())\n",
    "        }\n",
    "    price_summ = pd.DataFrame([\n",
    "        {\"source\":\"listings.price_num\", **price_summary(L.get('price_num', pd.Series(dtype=float)), 'listings')},\n",
    "        {\"source\":\"calendar.price_num\", **price_summary(C.get('price_num', pd.Series(dtype=float)), 'calendar')},\n",
    "    ])\n",
    "\n",
    "    # availability distribution & bad examples\n",
    "    avail_counts = None; bad_avail_examples = pd.DataFrame()\n",
    "    if 'available_norm' in C.columns:\n",
    "        avail_counts = C['available_norm'].value_counts(dropna=False).to_dict()\n",
    "        bad_mask = ~C['available_norm'].isin(['t','f'])\n",
    "        if bad_mask.any():\n",
    "            bad_avail_examples = C.loc[bad_mask, ['listing_id','date','available']].head(100)\n",
    "\n",
    "    metrics = {\n",
    "        \"rows_cols\": rows_cols,\n",
    "        \"duplicates\": {\"listings_id\": dup_list, \"calendar_pair\": dup_cal, \"reviews_keyed\": dup_rev},\n",
    "        \"referential\": {\"calendar_not_in_listings\": cal_missing, \"reviews_not_in_listings\": rev_missing},\n",
    "        \"date_ranges\": date_ranges,\n",
    "        \"review_mismatch_counts\": {\"first_review_mismatch\": first_mismatch, \"last_review_mismatch\": last_mismatch},\n",
    "        \"availability_counts\": avail_counts,\n",
    "    }\n",
    "\n",
    "    tables = {\n",
    "        \"missing_listings\": miss_L,\n",
    "        \"missing_calendar\": miss_C,\n",
    "        \"missing_reviews\":  miss_R,\n",
    "        \"bad_avail_examples\": bad_avail_examples,\n",
    "        \"rev_consistency_sample\": comp.head(50) if isinstance(comp, pd.DataFrame) else pd.DataFrame(),\n",
    "        \"price_summaries\": price_summ,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[Health] rows/cols:\", rows_cols)\n",
    "        print(\"[Health] duplicates:\", metrics[\"duplicates\"])\n",
    "        print(\"[Health] referential:\", metrics[\"referential\"])\n",
    "        print(\"[Health] availability counts:\", avail_counts)\n",
    "\n",
    "    return {\"metrics\": metrics, \"tables\": tables}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10516d94-9dea-4a15-8583-3881626c5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Deep-dive audit (structured returns) ===================================\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def run_deep_dive_audit(listings: pd.DataFrame, calendar: pd.DataFrame, reviews: pd.DataFrame, verbose=True):\n",
    "    C = calendar.copy(); L = listings.copy(); R = reviews.copy()\n",
    "    # guards\n",
    "    if 'available_norm' not in C.columns and 'available' in C.columns:\n",
    "        C['available_norm'] = C['available'].astype(str).str.lower().str.strip()\n",
    "    if 'price_num' not in C.columns and 'price' in C.columns:\n",
    "        C['price_num'] = (C['price'].astype(str).str.replace(r'[^0-9.\\-]','',regex=True)\n",
    "                          .replace({'':'nan','.' : 'nan'}).astype(float))\n",
    "\n",
    "    # 1) Price missingness by availability\n",
    "    miss_by_avail = (\n",
    "        C.assign(price_missing=C['price_num'].isna())\n",
    "         .groupby('available_norm', dropna=False)\n",
    "         .agg(rows=('price_missing','size'),\n",
    "              missing=('price_missing','sum'),\n",
    "              missing_pct=('price_missing', lambda s: 100*s.mean()))\n",
    "         .reset_index()\n",
    "    )\n",
    "\n",
    "    # 2) Occupancy per listing\n",
    "    C['booked'] = C['available_norm'].eq('f')\n",
    "    occ_by_listing = C.groupby('listing_id', as_index=True)['booked'].mean().to_frame('occupancy')\n",
    "\n",
    "    # 3) Date contiguity\n",
    "    span = (C.groupby('listing_id')\n",
    "              .agg(min_date=('date','min'),\n",
    "                   max_date=('date','max'),\n",
    "                   n_days=('date','nunique')))\n",
    "    span['expected_days'] = (span['max_date'] - span['min_date']).dt.days + 1\n",
    "    span['gaps'] = span['expected_days'] - span['n_days']\n",
    "    gap_summary = span['gaps'].describe(percentiles=[.5,.9,.99]).to_frame(name='gaps').T.round(3)\n",
    "    notable_gaps = span[span['gaps']>0].sort_values('gaps', ascending=False).head(50)\n",
    "\n",
    "    # 4) Reviews distribution\n",
    "    rev_counts = R.groupby('listing_id').size().rename('n_reviews')\n",
    "    rev_stats = rev_counts.describe(percentiles=[.5,.9,.99]).to_frame().T\n",
    "\n",
    "    # share of listings with ≥1 review\n",
    "    share_with_review = None\n",
    "    if 'id' in L.columns:\n",
    "        share_with_review = float((L[['id']].merge(rev_counts, left_on='id', right_index=True, how='left')\n",
    "                                   ['n_reviews'].fillna(0)>0).mean())\n",
    "\n",
    "    # 5) Median prices\n",
    "    med_listing_price  = float(pd.to_numeric(L.get('price_num', pd.Series(dtype=float)), errors='coerce').median(skipna=True)) \\\n",
    "                         if 'price_num' in L.columns else None\n",
    "    med_calendar_price = float(pd.to_numeric(C.get('price_num', pd.Series(dtype=float)), errors='coerce').median(skipna=True)) \\\n",
    "                         if 'price_num' in C.columns else None\n",
    "\n",
    "    # 6) Top neighborhoods\n",
    "    neigh_col = next((c for c in ['neighbourhood_cleansed','neighbourhood','neighbourhood_group_cleansed'] if c in L.columns), None)\n",
    "    top_neighborhoods = L[neigh_col].value_counts().head(10).to_frame('count') if neigh_col else pd.DataFrame()\n",
    "\n",
    "    metrics = {\n",
    "        \"occupancy\": {\n",
    "            \"N\": int(occ_by_listing.shape[0]),\n",
    "            \"mean\": float(occ_by_listing['occupancy'].mean()),\n",
    "            \"median\": float(occ_by_listing['occupancy'].median()),\n",
    "            \"p10\": float(occ_by_listing['occupancy'].quantile(0.10)),\n",
    "            \"p90\": float(occ_by_listing['occupancy'].quantile(0.90)),\n",
    "        },\n",
    "        \"gaps_max\": int(span['gaps'].max()),\n",
    "        \"share_with_review\": share_with_review,\n",
    "        \"median_prices\": {\"listings\": med_listing_price, \"calendar\": med_calendar_price},\n",
    "        \"neigh_col\": neigh_col,\n",
    "    }\n",
    "\n",
    "    tables = {\n",
    "        \"miss_by_avail\": miss_by_avail,\n",
    "        \"occ_by_listing\": occ_by_listing.reset_index(),\n",
    "        \"gap_summary\": gap_summary,\n",
    "        \"notable_gaps\": notable_gaps.reset_index(),\n",
    "        \"rev_stats\": rev_stats,\n",
    "        \"top_neighborhoods\": top_neighborhoods.reset_index().rename(columns={neigh_col:'neighborhood'}) if not top_neighborhoods.empty else pd.DataFrame(),\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"[DeepDive] occupancy (mean, median):\", metrics[\"occupancy\"][\"mean\"], metrics[\"occupancy\"][\"median\"])\n",
    "        print(\"[DeepDive] gaps max:\", metrics[\"gaps_max\"])\n",
    "\n",
    "    return {\"metrics\": metrics, \"tables\": tables}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f432e2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Health] rows/cols: {'listings_rows': 3818, 'listings_cols': 93, 'calendar_rows': 1393570, 'calendar_cols': 6, 'reviews_rows': 84849, 'reviews_cols': 6}\n",
      "[Health] duplicates: {'listings_id': 0, 'calendar_pair': 0, 'reviews_keyed': 0}\n",
      "[Health] referential: {'calendar_not_in_listings': 0, 'reviews_not_in_listings': 0}\n",
      "[Health] availability counts: {'t': 934542, 'f': 459028}\n",
      "[health_checks] Persisted for dataset_id='airbnb_seattle'.\n",
      "[DeepDive] occupancy (mean, median): 0.32938998399793334 0.15616438356164383\n",
      "[DeepDive] gaps max: 0\n",
      "[deep_dive_checks] Persisted for dataset_id='airbnb_seattle'.\n",
      "       dataset_id                computed_at  \\\n",
      "0  airbnb_seattle 2025-11-12 01:24:14.417738   \n",
      "\n",
      "                                             metrics  \n",
      "0  {\"rows_cols\": {\"listings_rows\": 3818, \"listing...  \n",
      "       dataset_id                computed_at  \\\n",
      "0  airbnb_seattle 2025-11-12 01:24:17.641173   \n",
      "\n",
      "                                             metrics  \n",
      "0  {\"occupancy\": {\"N\": 3818, \"mean\": 0.3293899839...  \n"
     ]
    }
   ],
   "source": [
    "# === Run & persist audits (no history) ======================================\n",
    "# Health audit\n",
    "health = run_health_audit(listings, calendar, reviews, verbose=True)\n",
    "persist_health_audit(health, dataset_id=\"airbnb_seattle\", overwrite=False)\n",
    "\n",
    "# Deep-dive audit\n",
    "deep = run_deep_dive_audit(listings, calendar, reviews, verbose=True)\n",
    "persist_deep_dive_audit(deep, dataset_id=\"airbnb_seattle\", overwrite=False)\n",
    "\n",
    "# Inspect what’s stored\n",
    "print(_con().execute(\"SELECT * FROM health_checks\").df())\n",
    "print(_con().execute(\"SELECT * FROM deep_dive_checks\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cb3db-afa1-4ee5-9ee2-9eb6a4ca15b2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === FUNCTION: train_regression_hgb (no run_id dependency) ===\n",
    "# Trains HGB on log(price), builds same features, optionally plots, and optionally saves plots\n",
    "# to a timestamped subfolder if save_dir is provided. Returns NO run_id.\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def train_regression_hgb(\n",
    "    listings_df: pd.DataFrame,\n",
    "    reviews_df: pd.DataFrame = None,\n",
    "    *,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "    plot: bool = True,\n",
    "    save_dir: str | Path | None = None,\n",
    "    top_k_importances: int = 20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a single HGB regression on log(price).\n",
    "\n",
    "    Returns a dict:\n",
    "      {\n",
    "        'model': fitted sklearn Pipeline,\n",
    "        'metrics': {'mae':..., 'rmse':..., 'r2_log':...},\n",
    "        'feat_importance': pd.Series (descending),\n",
    "        'test_predictions': pd.DataFrame(['id','y_true','y_pred']),\n",
    "        'artifacts': {'plots': [paths...]}  # if save_dir is provided\n",
    "      }\n",
    "    \"\"\"\n",
    "    df = listings_df.copy()\n",
    "\n",
    "    # --- Helpers ---\n",
    "    CITY_LAT, CITY_LON = 47.6062, -122.3321\n",
    "    SPACE_NEEDLE = (47.6205, -122.3493)\n",
    "    PIKE_PLACE   = (47.6094, -122.3421)\n",
    "\n",
    "    def haversine_km(lat1, lon1, lat2, lon2):\n",
    "        R = 6371.0\n",
    "        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "        a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "        return 2*R*np.arcsin(np.sqrt(a))\n",
    "\n",
    "    def tf_to_int(s):\n",
    "        return s.astype(str).str.lower().map({'t':1, 'f':0})\n",
    "\n",
    "    def has_amenity(series, keyword):\n",
    "        return series.fillna('').str.lower().str.contains(keyword.lower()).astype(int)\n",
    "\n",
    "    # Ensure numeric price exists\n",
    "    if 'price_num' not in df.columns and 'price' in df.columns:\n",
    "        df['price_num'] = (df['price'].astype(str)\n",
    "                           .str.replace(r'[^0-9.\\-]', '', regex=True)\n",
    "                           .replace({'': np.nan, '.': np.nan})\n",
    "                           .astype(float))\n",
    "\n",
    "    # Target\n",
    "    df = df[df['price_num'].notna()].copy()\n",
    "    df['target_price'] = df['price_num']\n",
    "    df['log_price'] = np.log1p(df['target_price'])\n",
    "\n",
    "    # Review count join (leak-free)\n",
    "    if reviews_df is not None:\n",
    "        rev_counts = reviews_df.groupby('listing_id').size().rename('n_reviews_actual')\n",
    "        df = df.merge(rev_counts, left_on='id', right_index=True, how='left')\n",
    "    else:\n",
    "        df['n_reviews_actual'] = np.nan\n",
    "    df['n_reviews_actual'] = df['n_reviews_actual'].fillna(0)\n",
    "\n",
    "    # Geo features\n",
    "    if {'latitude','longitude'}.issubset(df.columns):\n",
    "        df['dist_to_center_km']      = haversine_km(df['latitude'], df['longitude'], CITY_LAT, CITY_LON)\n",
    "        df['dist_to_spaceneedle_km'] = haversine_km(df['latitude'], df['longitude'], *SPACE_NEEDLE)\n",
    "        df['dist_to_pikeplace_km']   = haversine_km(df['latitude'], df['longitude'], *PIKE_PLACE)\n",
    "\n",
    "    # Percent strings → numeric\n",
    "    for pct_col in ['host_response_rate','host_acceptance_rate']:\n",
    "        if pct_col in df.columns:\n",
    "            df[pct_col + '_num'] = (df[pct_col].astype(str).str.rstrip('%')\n",
    "                                    .replace({'nan':np.nan}).astype(float))\n",
    "\n",
    "    # Amenities: count + flags\n",
    "    if 'amenities' in df.columns:\n",
    "        df['amenities_count'] = df['amenities'].fillna('').str.count(',') + df['amenities'].notna().astype(int)\n",
    "        for key in ['wifi','kitchen','parking','washer','dryer']:\n",
    "            df[f'amenity_{key}'] = has_amenity(df['amenities'], key)\n",
    "\n",
    "    # Text lengths\n",
    "    for text_col, newcol in [('description','desc_len'), ('name','name_len'), ('summary','summary_len')]:\n",
    "        if text_col in df.columns:\n",
    "            df[newcol] = df[text_col].fillna('').str.len()\n",
    "\n",
    "    # Host tenure + booleans\n",
    "    if {'host_since','last_scraped'}.issubset(df.columns):\n",
    "        df['host_since_days'] = (df['last_scraped'] - df['host_since']).dt.days\n",
    "    for c in ['host_is_superhost','instant_bookable','host_has_profile_pic','host_identity_verified']:\n",
    "        if c in df.columns:\n",
    "            df[c + '_bin'] = tf_to_int(df[c])\n",
    "\n",
    "    # Feature lists\n",
    "    num_candidates = [\n",
    "        'accommodates','bathrooms','bedrooms','beds',\n",
    "        'minimum_nights','maximum_nights',\n",
    "        'availability_365','number_of_reviews','n_reviews_actual',\n",
    "        'review_scores_rating','review_scores_cleanliness','review_scores_communication',\n",
    "        'review_scores_location','review_scores_value','review_scores_accuracy','review_scores_checkin',\n",
    "        'host_listings_count','host_total_listings_count',\n",
    "        'host_response_rate_num','host_acceptance_rate_num',\n",
    "        'amenities_count','amenity_wifi','amenity_kitchen','amenity_parking','amenity_washer','amenity_dryer',\n",
    "        'desc_len','name_len','summary_len',\n",
    "        'host_since_days','dist_to_center_km','dist_to_spaceneedle_km','dist_to_pikeplace_km',\n",
    "        'host_is_superhost_bin','instant_bookable_bin','host_has_profile_pic_bin','host_identity_verified_bin'\n",
    "    ]\n",
    "    cat_candidates = ['property_type','room_type','bed_type','neighbourhood_cleansed','cancellation_policy']\n",
    "\n",
    "    numeric_features = [c for c in num_candidates    if c in df.columns]\n",
    "    categorical_features = [c for c in cat_candidates if c in df.columns]\n",
    "\n",
    "    # Coerce numerics\n",
    "    for c in numeric_features:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    # Split\n",
    "    X = df[numeric_features + categorical_features].copy()\n",
    "    y_log   = df['log_price'].copy()\n",
    "    y_price = df['target_price'].copy()\n",
    "    ids = df.get('id', pd.Series(range(len(df))))\n",
    "\n",
    "    X_train, X_test, y_train_log, y_test_log, y_train_price, y_test_price, id_train, id_test = train_test_split(\n",
    "        X, y_log, y_price, ids, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Preprocess\n",
    "    try:\n",
    "        ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore', min_frequency=0.01)\n",
    "    except TypeError:\n",
    "        ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        ('num', SimpleImputer(strategy='median'), numeric_features),\n",
    "        ('cat', Pipeline([('impute', SimpleImputer(strategy='most_frequent')), ('ohe', ohe)]), categorical_features)\n",
    "    ], remainder='drop')\n",
    "\n",
    "    # Model\n",
    "    hgb = Pipeline([\n",
    "        ('pre', pre),\n",
    "        ('model', HistGradientBoostingRegressor(\n",
    "            max_iter=400, learning_rate=0.06, max_leaf_nodes=31, min_samples_leaf=20,\n",
    "            random_state=random_state\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Fit\n",
    "    hgb.fit(X_train, y_train_log)\n",
    "\n",
    "    # Evaluate\n",
    "    pred_log   = hgb.predict(X_test)\n",
    "    pred_price = np.expm1(pred_log)\n",
    "    mae  = mean_absolute_error(y_test_price, pred_price)\n",
    "    rmse = mean_squared_error(y_test_price, pred_price, squared=False)\n",
    "    r2lg = r2_score(y_test_log, pred_log)\n",
    "    metrics = {'mae': float(mae), 'rmse': float(rmse), 'r2_log': float(r2lg)}\n",
    "    print(f\"[HGB] MAE=${mae:,.2f}  RMSE=${rmse:,.2f}  R²(log)={r2lg:.3f}\")\n",
    "\n",
    "    # Permutation importance\n",
    "    try:\n",
    "        feat_names = hgb.named_steps['pre'].get_feature_names_out()\n",
    "    except Exception:\n",
    "        if categorical_features:\n",
    "            ohe_step = hgb.named_steps['pre'].named_transformers_['cat'].named_steps['ohe']\n",
    "            try:\n",
    "                cat_names = ohe_step.get_feature_names_out(categorical_features)\n",
    "            except Exception:\n",
    "                cat_names = np.array(categorical_features)\n",
    "            feat_names = np.r_[numeric_features, cat_names]\n",
    "        else:\n",
    "            feat_names = np.array(numeric_features)\n",
    "\n",
    "    pre_X_test = hgb.named_steps['pre'].transform(X_test)\n",
    "    if hasattr(pre_X_test, \"toarray\"):\n",
    "        pre_X_test = pre_X_test.toarray()\n",
    "\n",
    "    pi = permutation_importance(\n",
    "        hgb.named_steps['model'], pre_X_test, y_test_log,\n",
    "        n_repeats=5, random_state=random_state, n_jobs=-1\n",
    "    )\n",
    "    pi_mean = pd.Series(pi.importances_mean, index=feat_names).sort_values(ascending=False)\n",
    "\n",
    "    # Predictions table\n",
    "    preds_df = pd.DataFrame({\n",
    "        'id': np.array(id_test),\n",
    "        'y_true': np.array(y_test_price),\n",
    "        'y_pred': np.array(pred_price)\n",
    "    })\n",
    "\n",
    "    # Plots (optional)\n",
    "    saved_plots = []\n",
    "    if plot or save_dir:\n",
    "        # 1) Pred vs Actual\n",
    "        fig1 = plt.figure()\n",
    "        mx = float(max(preds_df['y_true'].max(), preds_df['y_pred'].max()))\n",
    "        plt.scatter(preds_df['y_true'], preds_df['y_pred'], s=9, alpha=0.5)\n",
    "        plt.plot([0, mx],[0, mx])\n",
    "        plt.xlabel(\"Actual price\"); plt.ylabel(\"Predicted price\"); plt.title(\"Predicted vs Actual (HGB)\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # 2) Residuals hist\n",
    "        fig2 = plt.figure()\n",
    "        resid = preds_df['y_true'] - preds_df['y_pred']\n",
    "        plt.hist(resid, bins=50, alpha=0.9)\n",
    "        plt.xlabel(\"Residual ($)\"); plt.ylabel(\"Count\"); plt.title(\"Residuals (HGB)\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_dir:\n",
    "            ts  = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            out = Path(save_dir) / f\"run_{ts}\"\n",
    "            out.mkdir(parents=True, exist_ok=True)\n",
    "            p1 = out / \"pred_vs_actual.png\"; p2 = out / \"residuals_hist.png\"\n",
    "            fig1.savefig(p1, dpi=120, bbox_inches='tight'); fig2.savefig(p2, dpi=120, bbox_inches='tight')\n",
    "            saved_plots += [str(p1), str(p2)]\n",
    "\n",
    "    # Console: top-k features\n",
    "    top = pi_mean.head(top_k_importances).round(4)\n",
    "    print(\"\\n[Permutation importance] Top features:\")\n",
    "    print(top.to_string())\n",
    "\n",
    "    return {\n",
    "        'model': hgb,\n",
    "        'metrics': metrics,\n",
    "        'feat_importance': pi_mean,\n",
    "        'test_predictions': preds_df,\n",
    "        'artifacts': {'plots': saved_plots}\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f18713-dfd7-45a0-9660-9c690870e102",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "def _make_preprocessor(numeric_features_in, categorical_features_in, scale_numeric=True):\n",
    "    # numeric pipeline\n",
    "    num_steps = [(\"impute\", SimpleImputer(strategy=\"median\"))]\n",
    "    if scale_numeric:\n",
    "        num_steps.append((\"scale\", StandardScaler()))\n",
    "    num_pipe = Pipeline(num_steps)\n",
    "\n",
    "    # categorical pipeline with safe OneHotEncoder\n",
    "    try:\n",
    "        ohe = OneHotEncoder(\n",
    "            handle_unknown=\"ignore\",\n",
    "            sparse_output=False,\n",
    "            min_frequency=0.01,\n",
    "        )\n",
    "    except TypeError:\n",
    "        # older sklearn: no sparse_output/min_frequency\n",
    "        ohe = OneHotEncoder(\n",
    "            handle_unknown=\"ignore\",\n",
    "            sparse=False,\n",
    "        )\n",
    "\n",
    "    cat_pipe = Pipeline(\n",
    "        [\n",
    "            (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", ohe),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pipe, numeric_features_in),\n",
    "            (\"cat\", cat_pipe, categorical_features_in),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )\n",
    "\n",
    "    return pre\n",
    "\n",
    "\n",
    "# === Logistic Regression (price-bucket) – class-balanced, 'saga' solver, metrics returned ===\n",
    "def run_logistic_price_bucket(\n",
    "    df_in=None,\n",
    "    numeric_features_in=None,\n",
    "    categorical_features_in=None,\n",
    "    price_quantile=0.75,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "):\n",
    "    import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (accuracy_score, classification_report, roc_auc_score,\n",
    "                                 confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support)\n",
    "\n",
    "    # --- resolve inputs ---\n",
    "    if df_in is None:\n",
    "        if \"df\" not in globals():\n",
    "            raise ValueError(\"No df supplied and global 'df' not found. Run the regression feature cell first.\")\n",
    "        df_local = df.copy()\n",
    "    else:\n",
    "        df_local = df_in.copy()\n",
    "\n",
    "    if numeric_features_in is None:\n",
    "        if \"numeric_features\" not in globals():\n",
    "            raise ValueError(\"numeric_features not available; pass explicitly or run regression feature cell.\")\n",
    "        numeric_features_in = numeric_features\n",
    "    if categorical_features_in is None:\n",
    "        if \"categorical_features\" not in globals():\n",
    "            raise ValueError(\"categorical_features not available; pass explicitly or run regression feature cell.\")\n",
    "        categorical_features_in = categorical_features\n",
    "\n",
    "    if \"target_price\" not in df_local.columns:\n",
    "        raise ValueError(\"df must contain 'target_price' (from regression prep).\")\n",
    "\n",
    "    # target\n",
    "    df_local = df_local[df_local[\"target_price\"].notna()].copy()\n",
    "    threshold = df_local[\"target_price\"].quantile(price_quantile)\n",
    "    df_local[\"is_high_price\"] = (df_local[\"target_price\"] >= threshold).astype(int)\n",
    "\n",
    "    X = df_local[numeric_features_in + categorical_features_in]\n",
    "    y = df_local[\"is_high_price\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    pre = _make_preprocessor(numeric_features_in, categorical_features_in, scale_numeric=True)\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"model\", LogisticRegression(\n",
    "            solver=\"saga\",            # robust with many OHE cols\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            class_weight=\"balanced\", # handle 75/25-ish split cleanly\n",
    "            max_iter=2000,\n",
    "            n_jobs=-1                # ignored by some solvers; harmless\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred  = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_proba)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", zero_division=0)\n",
    "\n",
    "    print(f\"High-price threshold (q={price_quantile:.2f}): ${threshold:,.0f}\")\n",
    "    print(f\"Accuracy: {acc:.3f} | ROC-AUC: {roc:.3f} | F1: {f1:.3f} (P={p:.3f}, R={r:.3f})\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ConfusionMatrixDisplay(cm, display_labels=[\"low\", \"high\"]).plot()\n",
    "    plt.title(\"High- vs low-price listings\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    metrics = {\"threshold\": float(threshold), \"accuracy\": float(acc), \"roc_auc\": float(roc),\n",
    "               \"precision\": float(p), \"recall\": float(r), \"f1\": float(f1)}\n",
    "\n",
    "    return clf, metrics\n",
    "\n",
    "\n",
    "\n",
    "# === KMeans clustering – safe display, silhouette guard, tidy returns ===\n",
    "def run_kmeans_clusters(\n",
    "    df_in=None,\n",
    "    numeric_features_in=None,\n",
    "    n_clusters=5,\n",
    "    random_state=42,\n",
    "):\n",
    "    import numpy as np, pandas as pd\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.cluster import KMeans\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "    except Exception:\n",
    "        display = print  # fallback\n",
    "\n",
    "    if df_in is None:\n",
    "        if \"df\" not in globals():\n",
    "            raise ValueError(\"No df supplied and global 'df' not found. Run the regression feature cell first.\")\n",
    "        df_local = df.copy()\n",
    "    else:\n",
    "        df_local = df_in.copy()\n",
    "\n",
    "    if numeric_features_in is None:\n",
    "        if \"numeric_features\" not in globals():\n",
    "            raise ValueError(\"numeric_features not available; pass explicitly or run regression feature cell.\")\n",
    "        numeric_features_in = numeric_features\n",
    "\n",
    "    df_local = df_local[df_local[\"target_price\"].notna()].copy()\n",
    "    X = df_local[numeric_features_in]\n",
    "\n",
    "    km_pipe = Pipeline([\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"kmeans\", KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)),\n",
    "    ])\n",
    "\n",
    "    labels = km_pipe.fit_predict(X)\n",
    "    df_clusters = df_local.copy()\n",
    "    df_clusters[\"cluster\"] = labels\n",
    "\n",
    "    # Silhouette (guard: need at least 2 clusters present)\n",
    "    sil = np.nan\n",
    "    if len(np.unique(labels)) > 1:\n",
    "        X_scaled = km_pipe.named_steps[\"scale\"].transform(km_pipe.named_steps[\"impute\"].transform(X))\n",
    "        sil = silhouette_score(X_scaled, labels)\n",
    "        print(f\"Silhouette score (k={n_clusters}): {sil:.3f}\")\n",
    "    else:\n",
    "        print(f\"Silhouette score skipped: only one cluster label found for k={n_clusters}.\")\n",
    "\n",
    "    cluster_summary = (\n",
    "        df_clusters.groupby(\"cluster\")[\"target_price\"]\n",
    "        .agg(count=\"size\", mean_price=\"mean\", median_price=\"median\")\n",
    "        .sort_values(\"mean_price\")\n",
    "    )\n",
    "    print(\"\\nCluster summary by target_price:\")\n",
    "    display(cluster_summary)\n",
    "\n",
    "    preview_cols = [\"id\", \"target_price\", \"cluster\"]\n",
    "    preview_cols = [c for c in preview_cols if c in df_clusters.columns]\n",
    "    preview = df_clusters[preview_cols].head(20)\n",
    "\n",
    "    metrics = {\"silhouette\": None if np.isnan(sil) else float(sil)}\n",
    "    return km_pipe, preview, cluster_summary, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e16827-720a-45ad-a985-3925904c024a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === One-and-done calendar forecaster: audit + train + evaluate + future forecast ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def run_calendar_forecast(calendar_df=None, data_dir=None, horizon=28, future_days=14,\n",
    "                          plot=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Time-series demand forecast from Airbnb calendar.\n",
    "    - Uses booked proxy: available == 'f'\n",
    "    - Trains HGB on booked_share with time features + lags/rolls\n",
    "    - Evaluates vs seasonal naive (t-7)\n",
    "    - Rolls forward for `future_days` beyond the last date\n",
    "\n",
    "    Returns dict with:\n",
    "      model, daily (raw city series), features (with lags), holdout_df, future_df, metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Load ----\n",
    "    if calendar_df is None:\n",
    "        paths = []\n",
    "        if data_dir is not None: paths.append(Path(data_dir) / 'calendar.csv')\n",
    "        paths.append(Path('calendar.csv'))\n",
    "        cal_path = next((p for p in paths if p.exists()), None)\n",
    "        if cal_path is None:\n",
    "            raise FileNotFoundError(\"calendar.csv not found. Pass `calendar_df` or set `data_dir`.\")\n",
    "        cal = pd.read_csv(cal_path)\n",
    "    else:\n",
    "        cal = calendar_df.copy()\n",
    "\n",
    "    # ---- Audit ----\n",
    "    cal.columns = cal.columns.str.lower()\n",
    "    for col in ['listing_id','date','available']:\n",
    "        if col not in cal.columns:\n",
    "            raise ValueError(f\"Required column missing: {col}\")\n",
    "    cal['date'] = pd.to_datetime(cal['date'], errors='coerce')\n",
    "    cal['available'] = cal['available'].astype(str).str.strip().str.lower()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"CALENDAR shape:\", cal.shape)\n",
    "        print(\"Missing (%):\\n\", (cal[['listing_id','date','available']].isna().mean()*100).round(2))\n",
    "        print(\"Duplicates (listing_id,date):\", int(cal.duplicated(['listing_id','date']).sum()))\n",
    "        print(\"Date range:\", cal['date'].min(), \"→\", cal['date'].max())\n",
    "\n",
    "    # ---- Aggregate to daily city series ----\n",
    "    cal['booked'] = cal['available'].eq('f')\n",
    "    daily = (cal.groupby('date', as_index=True, observed=True)\n",
    "               .agg(booked_count=('booked','sum'),\n",
    "                    total_listings=('listing_id','nunique')))\n",
    "    daily['booked_share'] = daily['booked_count'] / daily['total_listings']\n",
    "    daily = daily.asfreq('D')  # enforce daily frequency (your data is already contiguous)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nDaily head:\\n\", daily.head())\n",
    "        print(\"\\nBooked_share stats:\\n\", daily['booked_share'].describe().round(3))\n",
    "\n",
    "    # ---- Feature engineering ----\n",
    "    df = daily.copy()\n",
    "    idx = df.index\n",
    "    dow = idx.dayofweek.values\n",
    "    df['dow_sin'] = np.sin(2*np.pi*dow/7.0)\n",
    "    df['dow_cos'] = np.cos(2*np.pi*dow/7.0)\n",
    "    df['month']   = idx.month\n",
    "    df['t']       = (idx - idx.min()).days.astype(int)   # linear trend\n",
    "    try:\n",
    "        from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "        hol = USFederalHolidayCalendar().holidays(start=idx.min(), end=idx.max())\n",
    "        df['is_holiday'] = df.index.isin(hol).astype(int)\n",
    "    except Exception:\n",
    "        df['is_holiday'] = 0\n",
    "\n",
    "    for L in [1, 7, 14, 21, 28]:\n",
    "        df[f'lag_{L}'] = df['booked_share'].shift(L)\n",
    "    df['roll7']  = df['booked_share'].rolling(7,  min_periods=5).mean()\n",
    "    df['roll28'] = df['booked_share'].rolling(28, min_periods=10).mean()\n",
    "\n",
    "    dfm = df.dropna().copy()\n",
    "    if len(dfm) <= horizon + 1:\n",
    "        raise ValueError(\"Not enough history after lags for this horizon.\")\n",
    "\n",
    "    # ---- Train / test split (last `horizon` days) ----\n",
    "    train = dfm.iloc[:-horizon]\n",
    "    test  = dfm.iloc[-horizon:]\n",
    "    feats = ['dow_sin','dow_cos','month','t','is_holiday',\n",
    "             'lag_1','lag_7','lag_14','lag_21','lag_28','roll7','roll28']\n",
    "    X_tr, y_tr = train[feats], train['booked_share']\n",
    "    X_te, y_te = test[feats],  test['booked_share']\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_iter=700, learning_rate=0.05, max_leaf_nodes=31,\n",
    "        min_samples_leaf=8, random_state=42\n",
    "    ).fit(X_tr, y_tr)\n",
    "\n",
    "    # Predictions on holdout (share & count)\n",
    "    yhat_share = model.predict(X_te).clip(0, 1)\n",
    "    yhat_cnt   = (yhat_share * test['total_listings']).round()\n",
    "    ytrue_cnt  = test['booked_count']\n",
    "\n",
    "    # Seasonal naive\n",
    "    ynaive_share = test['lag_7'].values\n",
    "    ynaive_cnt   = (ynaive_share * test['total_listings']).round()\n",
    "\n",
    "    # Metrics\n",
    "    def mape(y, yhat):\n",
    "        y = np.asarray(y, float); yhat = np.asarray(yhat, float)\n",
    "        return np.mean(np.abs((y - yhat) / np.clip(y, 1e-6, None))) * 100\n",
    "\n",
    "    metrics = {\n",
    "        'mae_model':  float(mean_absolute_error(ytrue_cnt, yhat_cnt)),\n",
    "        'rmse_model': float(mean_squared_error(ytrue_cnt, yhat_cnt, squared=False)),\n",
    "        'mape_model': float(mape(ytrue_cnt, yhat_cnt)),\n",
    "        'mae_naive':  float(mean_absolute_error(ytrue_cnt, ynaive_cnt)),\n",
    "        'rmse_naive': float(mean_squared_error(ytrue_cnt, ynaive_cnt, squared=False)),\n",
    "        'mape_naive': float(mape(ytrue_cnt, ynaive_cnt)),\n",
    "    }\n",
    "    if verbose:\n",
    "        print(f\"\\nHoldout ({horizon}d) — \"\n",
    "              f\"Model MAE={metrics['mae_model']:.2f} RMSE={metrics['rmse_model']:.2f} MAPE={metrics['mape_model']:.2f}% | \"\n",
    "              f\"Naive MAE={metrics['mae_naive']:.2f} RMSE={metrics['rmse_naive']:.2f} MAPE={metrics['mape_naive']:.2f}%\")\n",
    "\n",
    "    # ---- Plots: train/test + share line (clean date labels) ----\n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(train.index, train['booked_count'], label='Train actual', linewidth=1)\n",
    "        ax.plot(test.index,  test['booked_count'],  label='Test actual', linewidth=2)\n",
    "        ax.plot(test.index,  yhat_cnt,              label='Model forecast', linewidth=2)\n",
    "        ax.plot(test.index,  ynaive_cnt,            label='Naive (t-7)', linestyle='--')\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.set_title(\"Daily booked (city-level)\")\n",
    "        ax.set_ylabel(\"Booked count\")\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.legend()\n",
    "        try:\n",
    "            locator = mdates.AutoDateLocator(minticks=4, maxticks=8)\n",
    "            ax.xaxis.set_major_locator(locator)\n",
    "            ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "        except Exception:\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "        for lbl in ax.get_xticklabels():\n",
    "            lbl.set_rotation(30); lbl.set_ha('right')\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig2, ax2 = plt.subplots()\n",
    "        ax2.plot(df.index, df['booked_share'])\n",
    "        ax2.set_ylim(bottom=0)\n",
    "        ax2.set_title(\"Booked share over time\")\n",
    "        ax2.set_ylabel(\"Share of listings booked\")\n",
    "        ax2.set_xlabel(\"Date\")\n",
    "        try:\n",
    "            locator = mdates.AutoDateLocator(minticks=6, maxticks=10)\n",
    "            ax2.xaxis.set_major_locator(locator)\n",
    "            ax2.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "        except Exception:\n",
    "            ax2.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "        for lbl in ax2.get_xticklabels():\n",
    "            lbl.set_rotation(30); lbl.set_ha('right')\n",
    "        fig2.tight_layout()\n",
    "\n",
    "    # ---- Future forecast (roll-forward) ----\n",
    "    future_rows = []\n",
    "    series = dfm['booked_share'].copy()                 # last known target series (with lags populated)\n",
    "    last_date, min_date = series.index[-1], series.index.min()\n",
    "    supply = int(dfm['total_listings'].iloc[-1])        # keep last observed supply\n",
    "    try:\n",
    "        from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "        hol = set(USFederalHolidayCalendar().holidays(start=min_date, end=last_date + pd.Timedelta(days=future_days)))\n",
    "    except Exception:\n",
    "        hol = set()\n",
    "\n",
    "    for i in range(1, future_days + 1):\n",
    "        d = last_date + pd.Timedelta(days=i)\n",
    "        dow = d.dayofweek\n",
    "        feat_row = {\n",
    "            'dow_sin': np.sin(2*np.pi*dow/7.0),\n",
    "            'dow_cos': np.cos(2*np.pi*dow/7.0),\n",
    "            'month':   d.month,\n",
    "            't':       (d - min_date).days,\n",
    "            'is_holiday': int(d in hol),\n",
    "            'lag_1':  series.iloc[-1],\n",
    "            'lag_7':  series.iloc[-7]  if len(series) >= 7  else series.iloc[-1],\n",
    "            'lag_14': series.iloc[-14] if len(series) >= 14 else series.iloc[-1],\n",
    "            'lag_21': series.iloc[-21] if len(series) >= 21 else series.iloc[-1],\n",
    "            'lag_28': series.iloc[-28] if len(series) >= 28 else series.iloc[-1],\n",
    "            'roll7':  series.tail(7).mean(),\n",
    "            'roll28': series.tail(28).mean(),\n",
    "        }\n",
    "        Xf = pd.DataFrame([feat_row], index=[d])\n",
    "        yhat_share_f = float(np.clip(model.predict(Xf)[0], 0, 1))\n",
    "        series.loc[d] = yhat_share_f\n",
    "        future_rows.append({'date': d,\n",
    "                            'pred_booked_share': yhat_share_f,\n",
    "                            'pred_booked_count': round(yhat_share_f * supply)})\n",
    "    future_df = pd.DataFrame(future_rows).set_index('date')\n",
    "\n",
    "    if plot:\n",
    "        fig3, ax3 = plt.subplots()\n",
    "        tail = dfm.tail(90)\n",
    "        ax3.plot(tail.index, tail['booked_count'], label='Recent actual', linewidth=1)\n",
    "        ax3.plot(future_df.index, future_df['pred_booked_count'], label=f'Forecast (+{future_days}d)', linewidth=2)\n",
    "        ax3.set_ylim(bottom=0)\n",
    "        ax3.set_title(f\"Forecast: booked count (next {future_days} days)\")\n",
    "        ax3.set_ylabel(\"Booked count\")\n",
    "        ax3.set_xlabel(\"Date\")\n",
    "        ax3.legend()\n",
    "        try:\n",
    "            locator = mdates.AutoDateLocator(minticks=4, maxticks=8)\n",
    "            ax3.xaxis.set_major_locator(locator)\n",
    "            ax3.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "        except Exception:\n",
    "            ax3.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
    "        for lbl in ax3.get_xticklabels():\n",
    "            lbl.set_rotation(30); lbl.set_ha('right')\n",
    "        fig3.tight_layout()\n",
    "\n",
    "    # ---- Build holdout table ----\n",
    "    holdout_df = pd.DataFrame({\n",
    "        'actual_booked': ytrue_cnt.values,\n",
    "        'model_forecast': yhat_cnt.values,\n",
    "        'naive_t7': ynaive_cnt.values\n",
    "    }, index=test.index)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'daily': daily,\n",
    "        'features': dfm,\n",
    "        'holdout_df': holdout_df,\n",
    "        'future_df': future_df,\n",
    "        'metrics': metrics\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc580f0-59a1-4f93-afbe-d0c72e4b24af",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === Multilingual review sentiment (ONE cell: audit → score → summarize → plots) ===\n",
    "# - Uses a multilingual transformer (CardiffNLP XLM-RoBERTa) for 3-way sentiment\n",
    "# - Falls back to VADER only if transformers/torch aren't available\n",
    "# - Returns compact artifacts you can reuse in the UI\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def run_review_sentiment_nlp(reviews_df=None, data_dir=None,\n",
    "                             model_name=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "                             batch_size=64, max_len=256, min_chars=5, plot=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Scores Airbnb reviews as positive / neutral / negative using a multilingual model.\n",
    "    Returns:\n",
    "      {\n",
    "        'reviews_scored': DataFrame[listening_id, date, sentiment_score, label, p_pos, p_neu, p_neg, comments_clean],\n",
    "        'listing_summary': per-listing % split + avg score,\n",
    "        'monthly_trend': monthly mean sentiment_score,\n",
    "        'overall_pct': overall % split\n",
    "      }\n",
    "    \"\"\"\n",
    "    # ---------- Load ----------\n",
    "    if reviews_df is None:\n",
    "        paths = []\n",
    "        if data_dir is not None: paths.append(Path(data_dir) / 'reviews.csv')\n",
    "        paths.append(Path('reviews.csv'))\n",
    "        rv_path = next((p for p in paths if p.exists()), None)\n",
    "        if rv_path is None:\n",
    "            raise FileNotFoundError(\"reviews.csv not found. Pass `reviews_df` or set `data_dir`.\")\n",
    "        reviews = pd.read_csv(rv_path)\n",
    "    else:\n",
    "        reviews = reviews_df.copy()\n",
    "\n",
    "    # ---------- Basic hygiene ----------\n",
    "    reviews.columns = reviews.columns.str.lower()\n",
    "    need = {'listing_id','date','comments'}\n",
    "    missing = need.difference(reviews.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Required columns missing from reviews: {missing}\")\n",
    "\n",
    "    reviews['date'] = pd.to_datetime(reviews['date'], errors='coerce')\n",
    "    before = len(reviews)\n",
    "    reviews = reviews.dropna(subset=['listing_id','date','comments'])\n",
    "    reviews = reviews[reviews['comments'].astype(str).str.len() >= min_chars].copy()\n",
    "    # conservative de-dup\n",
    "    dupe_keys = [c for c in ['listing_id','date','reviewer_id','comments'] if c in reviews.columns]\n",
    "    if len(dupe_keys) >= 2:\n",
    "        reviews = reviews.drop_duplicates(subset=dupe_keys)\n",
    "\n",
    "    # light cleaning\n",
    "    reviews['comments_clean'] = (reviews['comments'].astype(str)\n",
    "                                 .str.replace(r'\\s+', ' ', regex=True)\n",
    "                                 .str.strip())\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"REVIEWS shape: {len(reviews)} rows (dropped {before-len(reviews)})\")\n",
    "        print(\"Missingness (%):\")\n",
    "        print((reviews[['listing_id','date','comments_clean']].isna().mean()*100).round(2).rename('pct').to_string())\n",
    "        print(\"Date range:\", reviews['date'].min(), \"→\", reviews['date'].max())\n",
    "\n",
    "    # ---------- Sentiment model (multilingual) ----------\n",
    "    use_transformer = True\n",
    "    try:\n",
    "        from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "        import torch  # required backend\n",
    "    except Exception:\n",
    "        use_transformer = False\n",
    "\n",
    "    if use_transformer:\n",
    "        try:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "            clf = TextClassificationPipeline(model=model, tokenizer=tokenizer,\n",
    "                                             return_all_scores=True, truncation=True,\n",
    "                                             max_length=max_len, device=-1)\n",
    "        except Exception:\n",
    "            # If model download fails (e.g., no internet), fall back to VADER\n",
    "            use_transformer = False\n",
    "\n",
    "    if not use_transformer:\n",
    "        # VADER fallback\n",
    "        try:\n",
    "            from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "        except Exception:\n",
    "            import nltk\n",
    "            nltk.download('vader_lexicon', quiet=True)\n",
    "            from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # ---------- Score reviews in batches ----------\n",
    "    texts = reviews['comments_clean'].tolist()\n",
    "    n = len(texts)\n",
    "\n",
    "    p_pos = np.zeros(n, dtype=float)\n",
    "    p_neu = np.zeros(n, dtype=float)\n",
    "    p_neg = np.zeros(n, dtype=float)\n",
    "\n",
    "    if use_transformer:\n",
    "        # Helper to robustly map labels -> indices\n",
    "        def scores_to_triple(score_list):\n",
    "            # score_list = [{'label': 'negative', 'score': ...}, ...]\n",
    "            out = {'pos':0.0,'neu':0.0,'neg':0.0}\n",
    "            for d in score_list:\n",
    "                lab = str(d['label']).lower()\n",
    "                if 'pos' in lab: out['pos'] = float(d['score'])\n",
    "                elif 'neu' in lab: out['neu'] = float(d['score'])\n",
    "                elif 'neg' in lab or 'minus' in lab or lab.endswith('0'): out['neg'] = float(d['score'])\n",
    "            # normalize if something odd\n",
    "            s = out['pos'] + out['neu'] + out['neg']\n",
    "            if s > 0:\n",
    "                out = {k:v/s for k,v in out.items()}\n",
    "            return out['pos'], out['neu'], out['neg']\n",
    "\n",
    "        for i in range(0, n, batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            res = clf(batch, batch_size=batch_size)\n",
    "            # res is list (len=batch) of list-of-dicts\n",
    "            for j, sc in enumerate(res, start=i):\n",
    "                pp, pn, pg = scores_to_triple(sc)\n",
    "                p_pos[j], p_neu[j], p_neg[j] = pp, pn, pg\n",
    "    else:\n",
    "        # VADER path: convert compound to 3-way probs with simple thresholds\n",
    "        for i in range(n):\n",
    "            c = sia.polarity_scores(texts[i])['compound']\n",
    "            if c >= 0.05:\n",
    "                p_pos[i], p_neu[i], p_neg[i] = 1.0, 0.0, 0.0\n",
    "            elif c <= -0.05:\n",
    "                p_pos[i], p_neu[i], p_neg[i] = 0.0, 0.0, 1.0\n",
    "            else:\n",
    "                p_pos[i], p_neu[i], p_neg[i] = 0.0, 1.0, 0.0\n",
    "\n",
    "    # sentiment score in [-1, 1] similar to \"pos - neg\"\n",
    "    score = p_pos - p_neg\n",
    "    label_idx = np.argmax(np.c_[p_neg, p_neu, p_pos], axis=1)  # 0=neg,1=neu,2=pos\n",
    "    labels = np.array(['negative','neutral','positive'])[label_idx]\n",
    "\n",
    "    scored = reviews[['listing_id','date','comments_clean']].copy()\n",
    "    scored['sentiment_score'] = score\n",
    "    scored['label'] = labels\n",
    "    scored['p_pos'] = p_pos\n",
    "    scored['p_neu'] = p_neu\n",
    "    scored['p_neg'] = p_neg\n",
    "\n",
    "    # ---------- Aggregations ----------\n",
    "    total = len(scored)\n",
    "    overall = (scored['label'].value_counts()\n",
    "               .reindex(['positive','neutral','negative'])\n",
    "               .fillna(0).astype(int))\n",
    "    overall_pct = (overall / max(1,total) * 100).round(2)\n",
    "\n",
    "    listing_summary = (\n",
    "        scored.groupby('listing_id').agg(\n",
    "            n_reviews=('label','size'),\n",
    "            pos_pct=('label', lambda s: (s=='positive').mean()*100),\n",
    "            neu_pct=('label', lambda s: (s=='neutral').mean()*100),\n",
    "            neg_pct=('label', lambda s: (s=='negative').mean()*100),\n",
    "            avg_score=('sentiment_score','mean')\n",
    "        ).round({'pos_pct':2,'neu_pct':2,'neg_pct':2,'avg_score':3})\n",
    "        .sort_values('n_reviews', ascending=False)\n",
    "    )\n",
    "\n",
    "    monthly = scored.copy()\n",
    "    monthly['month'] = monthly['date'].dt.to_period('M').dt.to_timestamp()\n",
    "    monthly_trend = monthly.groupby('month')['sentiment_score'].mean().to_frame('mean_score')\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nOverall sentiment split (%):\")\n",
    "        print(overall_pct.dropna().to_string())\n",
    "        # sample examples\n",
    "        tops = scored.nlargest(3, 'sentiment_score')[['listing_id','date','sentiment_score','comments_clean']]\n",
    "        bots = scored.nsmallest(3, 'sentiment_score')[['listing_id','date','sentiment_score','comments_clean']]\n",
    "        print(\"\\nTop positive examples:\")\n",
    "        print(tops.assign(comments_clean=lambda s: s['comments_clean'].str.slice(0,120)+'…').to_string(index=False))\n",
    "        print(\"\\nTop negative examples:\")\n",
    "        print(bots.assign(comments_clean=lambda s: s['comments_clean'].str.slice(0,120)+'…').to_string(index=False))\n",
    "\n",
    "    # ---------- Plots ----------\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.hist(scored['sentiment_score'], bins=40, alpha=0.9)\n",
    "        plt.title(\"Review sentiment score\"); plt.xlabel(\"Score (-1 .. 1)\"); plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.figure()\n",
    "        order = ['positive','neutral','negative']\n",
    "        bars = scored['label'].value_counts().reindex(order).fillna(0)\n",
    "        plt.bar(bars.index.astype(str), bars.values)\n",
    "        plt.title(\"Sentiment label distribution\"); plt.ylabel(\"Reviews\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(monthly_trend.index, monthly_trend['mean_score'])\n",
    "        plt.title(\"Monthly mean sentiment score\"); plt.xlabel(\"Month\"); plt.ylabel(\"Mean score\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    return {\n",
    "        'reviews_scored': scored,\n",
    "        'listing_summary': listing_summary,\n",
    "        'monthly_trend': monthly_trend,\n",
    "        'overall_pct': overall_pct\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79db119-6e6c-4bf1-aafa-4af13337f88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HGB] MAE=$29.48  RMSE=$50.09  R²(log)=0.727\n",
      "\n",
      "[Permutation importance] Top features:\n",
      "cat__room_type_Entire home/apt    0.3848\n",
      "num__accommodates                 0.0894\n",
      "num__bedrooms                     0.0773\n",
      "num__dist_to_spaceneedle_km       0.0700\n",
      "num__bathrooms                    0.0509\n",
      "num__availability_365             0.0451\n",
      "cat__room_type_Private room       0.0346\n",
      "num__dist_to_pikeplace_km         0.0271\n",
      "num__host_since_days              0.0194\n",
      "num__review_scores_rating         0.0116\n",
      "num__minimum_nights               0.0106\n",
      "num__host_listings_count          0.0075\n",
      "num__number_of_reviews            0.0073\n",
      "num__dist_to_center_km            0.0064\n",
      "num__summary_len                  0.0060\n",
      "cat__room_type_Shared room        0.0038\n",
      "num__name_len                     0.0035\n",
      "num__maximum_nights               0.0034\n",
      "num__host_response_rate_num       0.0032\n",
      "num__host_is_superhost_bin        0.0030\n",
      "Saved regression run: 20251111-195133-regression-5317a26d -> artifacts\\regression\\20251111-195133-regression-5317a26d\n",
      "High-price threshold (q=0.75): $150\n",
      "Accuracy: 0.802 | ROC-AUC: 0.891 | F1: 0.677 (P=0.610, R=0.760)\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86       556\n",
      "           1       0.61      0.76      0.68       208\n",
      "\n",
      "    accuracy                           0.80       764\n",
      "   macro avg       0.76      0.79      0.77       764\n",
      "weighted avg       0.82      0.80      0.81       764\n",
      "\n",
      "Saved logistic run: 20251111-195147-logistic-8eb25d40 -> artifacts\\logistic\\20251111-195147-logistic-8eb25d40\n",
      "Silhouette score (k=5): 0.084\n",
      "\n",
      "Cluster summary by target_price:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_price</th>\n",
       "      <th>median_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1011</td>\n",
       "      <td>95.034619</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660</td>\n",
       "      <td>101.393939</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>258</td>\n",
       "      <td>116.391473</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1412</td>\n",
       "      <td>120.142351</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>477</td>\n",
       "      <td>264.031447</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_price  median_price\n",
       "cluster                                 \n",
       "1         1011   95.034619          85.0\n",
       "4          660  101.393939          90.0\n",
       "3          258  116.391473         100.0\n",
       "2         1412  120.142351         109.0\n",
       "0          477  264.031447         244.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved kmeans run: 20251111-195148-kmeans-7bc7fd20 -> artifacts\\kmeans\\20251111-195148-kmeans-7bc7fd20\n",
      "CALENDAR shape: (1393570, 6)\n",
      "Missing (%):\n",
      " listing_id    0.0\n",
      "date          0.0\n",
      "available     0.0\n",
      "dtype: float64\n",
      "Duplicates (listing_id,date): 0\n",
      "Date range: 2016-01-04 00:00:00 → 2017-01-02 00:00:00\n",
      "\n",
      "Daily head:\n",
      "             booked_count  total_listings  booked_share\n",
      "date                                                  \n",
      "2016-01-04          2083            3818      0.545574\n",
      "2016-01-05          1951            3818      0.511001\n",
      "2016-01-06          1992            3818      0.521739\n",
      "2016-01-07          2042            3818      0.534835\n",
      "2016-01-08          2036            3818      0.533263\n",
      "\n",
      "Booked_share stats:\n",
      " count    365.000\n",
      "mean       0.329\n",
      "std        0.048\n",
      "min        0.235\n",
      "25%        0.298\n",
      "50%        0.325\n",
      "75%        0.353\n",
      "max        0.546\n",
      "Name: booked_share, dtype: float64\n",
      "\n",
      "Holdout (28d) — Model MAE=38.21 RMSE=46.72 MAPE=3.90% | Naive MAE=21.79 RMSE=27.45 MAPE=2.20%\n",
      "Saved forecast run: 20251111-195241-forecast-4041cce6 -> artifacts\\forecast\\20251111-195241-forecast-4041cce6\n",
      "REVIEWS shape: 84791 rows (dropped 58)\n",
      "Missingness (%):\n",
      "listing_id        0.0\n",
      "date              0.0\n",
      "comments_clean    0.0\n",
      "Date range: 2009-06-07 00:00:00 → 2016-01-03 00:00:00\n",
      "\n",
      "Overall sentiment split (%):\n",
      "label\n",
      "positive    97.17\n",
      "neutral      1.87\n",
      "negative     0.97\n",
      "\n",
      "Top positive examples:\n",
      " listing_id       date  sentiment_score                                                                                                            comments_clean\n",
      "    7202016 2015-07-19              1.0                                                                     Cute and cozy place. Perfect location to everything!…\n",
      "    7202016 2015-07-20              1.0 Kelly has a great room in a very central location. Beautiful building , architecture and a style that we really like. We…\n",
      "    7202016 2015-07-26              1.0 Very spacious apartment, and in a great neighborhood. This is the kind of apartment I wish I had! Didn't really get to m…\n",
      "\n",
      "Top negative examples:\n",
      " listing_id       date  sentiment_score                                                                                                            comments_clean\n",
      "    3242605 2014-09-27             -1.0 Cozy and very private space! Close to beach, shopping, main street with restaurants. The only thing little uncomfortable…\n",
      "    1205666 2014-09-13             -1.0 Es war wundervoll bei Sean und seiner Familie. Das Zimmer ist perfekt von der Größe und wir haben uns sehr willkommen ge…\n",
      "    1205666 2015-08-25             -1.0 Sean, Carla & Sohn waren wirklich ganz tolle Gastgeber. Es waren unsere ersten zwei Nächte mit einer Buchung via AIRBNB …\n",
      "Saved NLP run: 20251111-195431-nlp-586882ad -> artifacts\\nlp\\20251111-195431-nlp-586882ad\n",
      "                                run_id  model_type                 started_at  \\\n",
      "0         20251111-195431-nlp-586882ad         nlp 2025-11-11 19:54:31.758662   \n",
      "1    20251111-195241-forecast-4041cce6    forecast 2025-11-11 19:52:41.496239   \n",
      "2      20251111-195148-kmeans-7bc7fd20      kmeans 2025-11-11 19:51:48.857780   \n",
      "3    20251111-195147-logistic-8eb25d40    logistic 2025-11-11 19:51:47.500303   \n",
      "4  20251111-195133-regression-5317a26d  regression 2025-11-11 19:51:34.519592   \n",
      "\n",
      "                    ended_at     status  \\\n",
      "0 2025-11-11 19:54:33.534726  succeeded   \n",
      "1 2025-11-11 19:52:43.577904  succeeded   \n",
      "2 2025-11-11 19:51:49.499070  succeeded   \n",
      "3 2025-11-11 19:51:48.014722  succeeded   \n",
      "4 2025-11-11 19:51:41.886665  succeeded   \n",
      "\n",
      "                                              params  \\\n",
      "0  {\"model_name\": \"cardiffnlp/twitter-xlm-roberta...   \n",
      "1  {\"city\": \"Seattle\", \"horizon\": 28, \"future_day...   \n",
      "2                                                 {}   \n",
      "3                                                 {}   \n",
      "4                                                 {}   \n",
      "\n",
      "                                             metrics      dataset_id notes  \n",
      "0  {\"positive\": 97.17, \"neutral\": 1.87, \"negative...  airbnb_seattle  None  \n",
      "1  {\"mae_model\": 38.214285714285715, \"rmse_model\"...  airbnb_seattle  None  \n",
      "2                {\"silhouette\": 0.08429185201775467}  airbnb_seattle  None  \n",
      "3  {\"threshold\": 150.0, \"accuracy\": 0.80235602094...  airbnb_seattle  None  \n",
      "4  {\"mae\": 29.48116705374614, \"rmse\": 50.09331900...  airbnb_seattle  None  \n",
      "                                run_id  model_type                 started_at  \\\n",
      "0  20251111-195133-regression-5317a26d  regression 2025-11-11 19:51:34.519592   \n",
      "\n",
      "                    ended_at     status params  \\\n",
      "0 2025-11-11 19:51:41.886665  succeeded     {}   \n",
      "\n",
      "                                             metrics      dataset_id notes  \n",
      "0  {\"mae\": 29.48116705374614, \"rmse\": 50.09331900...  airbnb_seattle  None  \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Filesystem helpers ----------\n",
    "def _make_outdir(model_type, run_id):\n",
    "    out = ART_ROOT / model_type / run_id\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    return out\n",
    "\n",
    "def save_current_figures(out_dir, prefix):\n",
    "    saved = []\n",
    "    for i, fignum in enumerate(plt.get_fignums(), start=1):\n",
    "        fig = plt.figure(fignum)\n",
    "        p = Path(out_dir) / f\"{prefix}_{i}.png\"\n",
    "        fig.savefig(p, dpi=120, bbox_inches='tight')\n",
    "        plt.close(fig)  # closes as we go\n",
    "        saved.append(str(p))\n",
    "    return saved\n",
    "\n",
    "# ---------- Persistors for your three models ----------\n",
    "def persist_regression_outputs(art_reg, params=None, dataset_id=\"airbnb_seattle\"):\n",
    "    \"\"\"\n",
    "    art_reg: dict returned by train_regression_hgb(...)\n",
    "      keys used: 'model', 'metrics', 'feat_importance'(Series), 'test_predictions'(DataFrame), 'artifacts'\n",
    "    \"\"\"\n",
    "    model_type = \"regression\"\n",
    "    run_id = start_run(model_type, params=params, dataset_id=dataset_id)\n",
    "    try:\n",
    "        out = _make_outdir(model_type, run_id)\n",
    "\n",
    "        # Save model\n",
    "        model_path = out / \"model.joblib\"\n",
    "        joblib.dump(art_reg['model'], model_path)\n",
    "        log_artifact(run_id, model_path, 'model', 'Sklearn pipeline')\n",
    "\n",
    "        # Save metrics JSON into DB (end_run handles it), also write a copy to disk\n",
    "        metrics_path = out / \"metrics.json\"\n",
    "        with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(art_reg.get('metrics', {}), f, indent=2)\n",
    "        log_artifact(run_id, metrics_path, 'text', 'Metrics JSON')\n",
    "\n",
    "        # Save feature importance + test predictions\n",
    "        if isinstance(art_reg.get('feat_importance'), pd.Series):\n",
    "            fi_path = out / \"feature_importance.parquet\"\n",
    "            art_reg['feat_importance'].rename(\"importance\").to_frame().to_parquet(fi_path)\n",
    "            log_artifact(run_id, fi_path, 'table', 'Permutation importance')\n",
    "\n",
    "        if isinstance(art_reg.get('test_predictions'), pd.DataFrame):\n",
    "            pred_path = out / \"test_predictions.parquet\"\n",
    "            art_reg['test_predictions'].to_parquet(pred_path)\n",
    "            log_artifact(run_id, pred_path, 'table', 'Test predictions')\n",
    "\n",
    "        # Save any already-saved plots from the training function\n",
    "        for p in art_reg.get('artifacts', {}).get('plots', []):\n",
    "            if Path(p).exists():\n",
    "                log_artifact(run_id, p, 'plot', 'Plot from training cell')\n",
    "\n",
    "        # Also capture any currently open figures (e.g., if plot=True)\n",
    "        for p in save_current_figures(out, prefix=\"reg_plot\"):\n",
    "            log_artifact(run_id, p, 'plot', 'Saved current matplotlib figure')\n",
    "        \n",
    "        end_run(run_id, 'succeeded', metrics=art_reg.get('metrics', {}))\n",
    "        return run_id, str(out)\n",
    "    except Exception as e:\n",
    "        end_run(run_id, 'failed', notes=str(e))\n",
    "        raise\n",
    "\n",
    "def persist_logistic_outputs(clf, metrics: dict, params=None, dataset_id=\"airbnb_seattle\"):\n",
    "    \"\"\"\n",
    "    clf: Pipeline returned by run_logistic_price_bucket(...)\n",
    "    metrics: dict returned by run_logistic_price_bucket(...)\n",
    "    Captures the confusion matrix figure already drawn by your function.\n",
    "    \"\"\"\n",
    "    model_type = \"logistic\"\n",
    "    run_id = start_run(model_type, params=params, dataset_id=dataset_id)\n",
    "    try:\n",
    "        out = _make_outdir(model_type, run_id)\n",
    "\n",
    "        # Save model\n",
    "        model_path = out / \"model.joblib\"\n",
    "        joblib.dump(clf, model_path)\n",
    "        log_artifact(run_id, model_path, 'model', 'Logistic pipeline')\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_path = out / \"metrics.json\"\n",
    "        with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metrics or {}, f, indent=2)\n",
    "        log_artifact(run_id, metrics_path, 'text', 'Metrics JSON')\n",
    "\n",
    "        # Save any open figures (e.g., ConfusionMatrixDisplay)\n",
    "        for p in save_current_figures(out, prefix=\"logistic_plot\"):\n",
    "            log_artifact(run_id, p, 'plot', 'Saved current matplotlib figure')\n",
    "        \n",
    "        end_run(run_id, 'succeeded', metrics=metrics or {})\n",
    "        return run_id, str(out)\n",
    "    except Exception as e:\n",
    "        end_run(run_id, 'failed', notes=str(e))\n",
    "        raise\n",
    "\n",
    "def persist_kmeans_outputs(km_pipe, preview: pd.DataFrame, cluster_summary: pd.DataFrame,\n",
    "                           metrics: dict, params=None, dataset_id=\"airbnb_seattle\"):\n",
    "    \"\"\"\n",
    "    km_pipe: Pipeline from run_kmeans_clusters(...)\n",
    "    preview: small sample df\n",
    "    cluster_summary: groupby summary\n",
    "    metrics: {'silhouette': ...}\n",
    "    \"\"\"\n",
    "    model_type = \"kmeans\"\n",
    "    run_id = start_run(model_type, params=params, dataset_id=dataset_id)\n",
    "    try:\n",
    "        out = _make_outdir(model_type, run_id)\n",
    "\n",
    "        # Save model\n",
    "        model_path = out / \"model.joblib\"\n",
    "        joblib.dump(km_pipe, model_path)\n",
    "        log_artifact(run_id, model_path, 'model', 'KMeans pipeline')\n",
    "\n",
    "        # Save tables\n",
    "        if isinstance(preview, pd.DataFrame):\n",
    "            prev_path = out / \"preview.parquet\"\n",
    "            preview.to_parquet(prev_path)\n",
    "            log_artifact(run_id, prev_path, 'table', 'Cluster preview')\n",
    "\n",
    "        if isinstance(cluster_summary, pd.DataFrame):\n",
    "            summ_path = out / \"cluster_summary.parquet\"\n",
    "            cluster_summary.to_parquet(summ_path)\n",
    "            log_artifact(run_id, summ_path, 'table', 'Cluster summary')\n",
    "\n",
    "        # Save metrics\n",
    "        metrics_path = out / \"metrics.json\"\n",
    "        with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(metrics or {}, f, indent=2)\n",
    "        log_artifact(run_id, metrics_path, 'text', 'Metrics JSON')\n",
    "\n",
    "        # Save any open figures (if you plotted something)\n",
    "        for p in save_current_figures(out, prefix=\"kmeans_plot\"):\n",
    "            log_artifact(run_id, p, 'plot', 'Saved current matplotlib figure')\n",
    "\n",
    "        end_run(run_id, 'succeeded', metrics=metrics or {})\n",
    "        return run_id, str(out)\n",
    "    except Exception as e:\n",
    "        end_run(run_id, 'failed', notes=str(e))\n",
    "        raise\n",
    "def persist_forecast_outputs(art, params=None, dataset_id=\"airbnb_seattle\",\n",
    "                             horizon=None, future_days=None):\n",
    "    \"\"\"\n",
    "    art: dict returned by run_calendar_forecast(...)\n",
    "         keys used: 'model','metrics','daily','features','holdout_df','future_df'\n",
    "    \"\"\"\n",
    "    assert all(k in art for k in ['model','metrics','daily','features','holdout_df','future_df']), \\\n",
    "        \"Missing keys in forecast artifacts. Run run_calendar_forecast(...) first.\"\n",
    "\n",
    "    model_type = \"forecast\"\n",
    "    # fold horizon/future_days into params (if caller passes them)\n",
    "    p = dict(params or {})\n",
    "    if horizon is not None: p['horizon'] = int(horizon)\n",
    "    if future_days is not None: p['future_days'] = int(future_days)\n",
    "\n",
    "    run_id = start_run(model_type, params=p, dataset_id=dataset_id)\n",
    "    try:\n",
    "        out = _make_outdir(model_type, run_id)\n",
    "\n",
    "        # --- Save model ---\n",
    "        model_path = out / \"model.joblib\"\n",
    "        joblib.dump(art['model'], model_path)\n",
    "        log_artifact(run_id, model_path, 'model', 'HGB forecaster')\n",
    "\n",
    "        # --- Save metrics JSON ---\n",
    "        metrics_path = out / \"metrics.json\"\n",
    "        with open(metrics_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(art.get('metrics', {}), f, indent=2)\n",
    "        log_artifact(run_id, metrics_path, 'text', 'Metrics JSON')\n",
    "\n",
    "        # --- Save tables ---\n",
    "        daily_path   = out / \"daily.parquet\"\n",
    "        feats_path   = out / \"features.parquet\"\n",
    "        holdout_path = out / \"holdout.parquet\"\n",
    "        future_path  = out / \"future.parquet\"\n",
    "\n",
    "        art['daily'].to_parquet(daily_path)\n",
    "        art['features'].to_parquet(feats_path)\n",
    "        art['holdout_df'].to_parquet(holdout_path)\n",
    "        art['future_df'].to_parquet(future_path)\n",
    "\n",
    "        log_artifact(run_id, daily_path,   'table', 'City daily series')\n",
    "        log_artifact(run_id, feats_path,   'table', 'Feature matrix (lags/rolls)')\n",
    "        log_artifact(run_id, holdout_path, 'table', 'Holdout predictions')\n",
    "        log_artifact(run_id, future_path,  'table', 'Future forecast')\n",
    "\n",
    "        # --- Save any open figures (train/test plots, forecast plot) ---\n",
    "        for pth in save_current_figures(out, prefix=\"forecast_plot\"):\n",
    "            log_artifact(run_id, pth, 'plot', 'Saved matplotlib figure')\n",
    "\n",
    "        end_run(run_id, 'succeeded', metrics=art.get('metrics', {}))\n",
    "        return run_id, str(out)\n",
    "    except Exception as e:\n",
    "        end_run(run_id, 'failed', notes=str(e))\n",
    "        raise\n",
    "\n",
    "\n",
    "def persist_nlp_outputs(nlp_art, params=None, dataset_id=\"airbnb_seattle\",\n",
    "                        model_name=None, engine=None):\n",
    "    \"\"\"\n",
    "    nlp_art: dict returned by run_review_sentiment_nlp(...)\n",
    "             keys used: 'reviews_scored','listing_summary','monthly_trend','overall_pct'\n",
    "    model_name/engine: optional metadata (e.g., HF model id or 'vader') to store with the run.\n",
    "    \"\"\"\n",
    "    assert all(k in nlp_art for k in ['reviews_scored','listing_summary','monthly_trend','overall_pct']), \\\n",
    "        \"Missing keys in NLP artifacts. Run run_review_sentiment_nlp(...) first.\"\n",
    "\n",
    "    model_type = \"nlp\"\n",
    "    meta = dict(params or {})\n",
    "    if model_name is not None: meta['model_name'] = model_name\n",
    "    if engine is not None:     meta['engine'] = engine\n",
    "\n",
    "    run_id = start_run(model_type, params=meta, dataset_id=dataset_id)\n",
    "    try:\n",
    "        out = _make_outdir(model_type, run_id)\n",
    "\n",
    "        # --- Save rollups/tables ---\n",
    "        scored_path  = out / \"reviews_scored.parquet\"\n",
    "        list_path    = out / \"listing_summary.parquet\"\n",
    "        trend_path   = out / \"monthly_trend.parquet\"\n",
    "        overall_path = out / \"overall_pct.json\"\n",
    "\n",
    "        nlp_art['reviews_scored'].to_parquet(scored_path)\n",
    "        nlp_art['listing_summary'].to_parquet(list_path)\n",
    "        nlp_art['monthly_trend'].to_parquet(trend_path)\n",
    "        with open(overall_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({k: float(v) for k,v in nlp_art['overall_pct'].items()}, f, indent=2)\n",
    "\n",
    "        log_artifact(run_id, scored_path,  'table', 'Per-review sentiment')\n",
    "        log_artifact(run_id, list_path,    'table', 'Per-listing sentiment summary')\n",
    "        log_artifact(run_id, trend_path,   'table', 'Monthly sentiment trend')\n",
    "        log_artifact(run_id, overall_path, 'text',  'Overall sentiment split (%)')\n",
    "\n",
    "        # --- Save any open figures (hist, bar, monthly plot) ---\n",
    "        for pth in save_current_figures(out, prefix=\"nlp_plot\"):\n",
    "            log_artifact(run_id, pth, 'plot', 'Saved matplotlib figure')\n",
    "\n",
    "        # --- Compose minimal metrics to store in runs table ---\n",
    "        # Use overall split as metrics (handy for dashboard)\n",
    "        metrics = {k: float(v) for k, v in nlp_art['overall_pct'].items()}\n",
    "        end_run(run_id, 'succeeded', metrics=metrics)\n",
    "        return run_id, str(out)\n",
    "    except Exception as e:\n",
    "        end_run(run_id, 'failed', notes=str(e))\n",
    "        raise\n",
    "# ---------- Minimal examples (call right after training) ----------\n",
    "# 1) Regression:\n",
    "art_reg = train_regression_hgb(listings_df=listings, reviews_df=reviews, plot=True, save_dir=\"artifacts/regression\")\n",
    "run_id_reg, out_reg = persist_regression_outputs(art_reg)\n",
    "print(\"Saved regression run:\", run_id_reg, \"->\", out_reg)\n",
    "\n",
    "# 2) Logistic:\n",
    "clf, cls_metrics = run_logistic_price_bucket()\n",
    "run_id_cls, out_cls = persist_logistic_outputs(clf, cls_metrics)\n",
    "print(\"Saved logistic run:\", run_id_cls, \"->\", out_cls)\n",
    "\n",
    "# 3) KMeans:\n",
    "km_pipe, preview, cluster_summary, km_metrics = run_kmeans_clusters(n_clusters=5)\n",
    "run_id_km, out_km = persist_kmeans_outputs(km_pipe, preview, cluster_summary, km_metrics)\n",
    "print(\"Saved kmeans run:\", run_id_km, \"->\", out_km)\n",
    "\n",
    "\n",
    "\n",
    "# Forecast:\n",
    "art = run_calendar_forecast(calendar_df=calendar, horizon=28, future_days=14, plot=True, verbose=True)\n",
    "run_id_fc, out_fc = persist_forecast_outputs(art, params={'city':'Seattle'}, horizon=28, future_days=14)\n",
    "print(\"Saved forecast run:\", run_id_fc, \"->\", out_fc)\n",
    "\n",
    "# NLP:\n",
    "nlp_art = run_review_sentiment_nlp(reviews_df=reviews, plot=True, verbose=True)\n",
    "run_id_nlp, out_nlp = persist_nlp_outputs(nlp_art, model_name=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\", engine=\"transformer\")\n",
    "print(\"Saved NLP run:\", run_id_nlp, \"->\", out_nlp)\n",
    "\n",
    "# Inspect history:\n",
    "print(runs_history())\n",
    "print(latest_run(\"regression\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f26d100-a90b-4cce-b37a-66e61a8dfd45",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
